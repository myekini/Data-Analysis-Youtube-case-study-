{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34d46248",
   "metadata": {},
   "source": [
    "<img src=\"youtube.png\" width=\"100\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcba413",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Text Data Analysis (Youtube case Study)</h1>\n",
    "\n",
    "\n",
    "- Sentimental Analysis.\n",
    "- Dislike vs Views Analysis.\n",
    "- Trending Video tags on youtube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a20a884d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e650636b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (23.1)\n",
      "Collecting pip\n",
      "  Using cached pip-23.2.1-py3-none-any.whl (2.1 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: To modify pip, please run the following command:\n",
      "C:\\Python311\\python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 23.1 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Using cached textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "Collecting nltk>=3.1 (from textblob)\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 762.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: click in c:\\python311\\lib\\site-packages (from nltk>=3.1->textblob) (8.1.3)\n",
      "Collecting joblib (from nltk>=3.1->textblob)\n",
      "  Downloading joblib-1.3.1-py3-none-any.whl (301 kB)\n",
      "     ------------------------------------ 302.0/302.0 kB 932.0 kB/s eta 0:00:00\n",
      "Collecting regex>=2021.8.3 (from nltk>=3.1->textblob)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /simple/regex/\n",
      "  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000002AA8B8D4690>, 'Connection to files.pythonhosted.org timed out. (connect timeout=15)')': /packages/50/6a/cd59b2e1d6817858e3f332b4128e9246bf8408a7a791f8b77b08633a959d/regex-2023.6.3-cp311-cp311-win_amd64.whl\n",
      "  WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000002AA8B8D5350>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /packages/50/6a/cd59b2e1d6817858e3f332b4128e9246bf8408a7a791f8b77b08633a959d/regex-2023.6.3-cp311-cp311-win_amd64.whl\n",
      "  WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000002AA8C22BF10>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /packages/50/6a/cd59b2e1d6817858e3f332b4128e9246bf8408a7a791f8b77b08633a959d/regex-2023.6.3-cp311-cp311-win_amd64.whl\n",
      "  WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000002AA8C234650>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /packages/50/6a/cd59b2e1d6817858e3f332b4128e9246bf8408a7a791f8b77b08633a959d/regex-2023.6.3-cp311-cp311-win_amd64.whl\n",
      "  WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000002AA8C234D90>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /packages/50/6a/cd59b2e1d6817858e3f332b4128e9246bf8408a7a791f8b77b08633a959d/regex-2023.6.3-cp311-cp311-win_amd64.whl\n",
      "ERROR: Could not install packages due to an OSError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Max retries exceeded with url: /packages/50/6a/cd59b2e1d6817858e3f332b4128e9246bf8408a7a791f8b77b08633a959d/regex-2023.6.3-cp311-cp311-win_amd64.whl (Caused by NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000002AA8C235390>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\n",
      "\n",
      "\n",
      "[notice] A new release of pip is available: 23.1 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install textblob\n",
    "!pip install pandas numpy matplotlib seaborn \n",
    "!pip install emoji\n",
    "!pip install plotly\n",
    "!pip install chart_studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17184c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('UScomments.csv', on_bad_lines=\"skip\",encoding='latin-1', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce498a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48072721",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    " cleaning data, finding missing values and outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1cff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccca3eb8",
   "metadata": {},
   "source": [
    "## Sentimental Analysis\n",
    " we're to find out the polarity , subjectivity of comments from youtube case study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acda592d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "polarity = []\n",
    "\n",
    "for comment in df['comment_text']:\n",
    "    polarity.append(TextBlob(comment).sentiment.polarity)\n",
    "\n",
    "df['polarity'] = polarity\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33e6dd5",
   "metadata": {},
   "source": [
    "## WordCloud Representation of sentiment analysis\n",
    "identifying the positive, negetive comments from the youtube case study and plotting a worcloud to better visualize the distict comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985ca247",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install wordcloud\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# collecting the positive and negative comments\n",
    "positive_comments = df[df['polarity'] == 1]\n",
    "negative_comments = df[df['polarity'] == -1]\n",
    "\n",
    "# wordcloud recieves a string as value (convert series in dataframe to string)\n",
    "total_comments1 = ' '.join(positive_comments['comment_text'])\n",
    "total_comments2 = ' '.join(negative_comments['comment_text'])\n",
    "\n",
    "# wordcloud representing of positive comments\n",
    "stopword = stopwords.words('english')\n",
    "word_cloud = WordCloud(stopwords=stopword).generate(total_comments1)\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.imshow(word_cloud)\n",
    "plt.axis('off')\n",
    "\n",
    "# wordcloud representing of negative comments\n",
    "word_cloud = WordCloud(stopwords=stopword).generate(total_comments2)\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.imshow(word_cloud)\n",
    "plt.axis('off')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3360abd",
   "metadata": {},
   "source": [
    "## Emoji Analysis\n",
    " performing analysis on emoji's on youtube case study to determine dislikes and views from users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0b3d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import emoji\n",
    "from plotly.offline import iplot\n",
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objects as go\n",
    "from collections import Counter\n",
    "\n",
    "emoji_list = []\n",
    "for comment in df['comment_text']:\n",
    "    for c in comment:\n",
    "        if c in emoji.EMOJI_DATA:\n",
    "            emoji_list.append(c)\n",
    "            \n",
    "# most common emojis in comment\n",
    "freq = [Counter(emoji_list).most_common(10)[i][1] for i in range(10)]\n",
    "\n",
    "#plot frequency of emojis\n",
    "trace = go.Figure(\n",
    "        data=[go.Bar(x=emoji_list, y =freq)],\n",
    "        layout_title_text=\"A Figure Displayed with fig.show()\"\n",
    ")\n",
    "trace.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa63709",
   "metadata": {},
   "source": [
    "## Collect entire data from youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc6affa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = r\"C:\\Users\\USER\\Downloads\\PERSONAL DEV\\Data Analytics\\Datasets\\additional_data\"\n",
    "files = os.listdir(path)\n",
    "\n",
    "# extract the csv files from the list of data\n",
    "full_df = pd.DataFrame()\n",
    "file_csv = [files[i] for i in range(0, len(files), 2)]   # within the range of 0 and the length of csv file using step 2\n",
    "\n",
    "for file in file_csv:\n",
    "    current_df = pd.read_csv(path+ \"\\\\\" +file, encoding=\"ISO-8859-1\", error_bad_lines=False)\n",
    "    current_df['country'] = file.split('.')[0][0:2]\n",
    "    full_df = pd.concat([full_df, current_df])\n",
    "    \n",
    "full_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d5ae18",
   "metadata": {},
   "source": [
    "## Analysing the most Liked category\n",
    " peforming analysis on the most liked category of youtube videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39904f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read out ctaerogi\n",
    "category_df = pd.read_csv(r'C:\\Users\\USER\\Downloads\\PERSONAL DEV\\Data Analytics\\Datasets\\category_file.txt', sep=':')\n",
    "category_df.reset_index(inplace=True)\n",
    "category_df.columns = ['category_id', 'category_name']\n",
    "category_df.set_index('category_id', inplace=True)\n",
    "category_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f48f5e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
